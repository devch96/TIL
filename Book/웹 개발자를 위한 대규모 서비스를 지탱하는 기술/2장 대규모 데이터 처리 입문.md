# 대규모 데이터 처리 입문

---------

## 대규모 데이터 처리의 어려운 점

### 대규모 데이터는 어떤 점이 어려운가?

- 메모리 내에서 계산할 수 없다
  - 메모리에 올리지 않으면 기본적으로 디스크를 계속 읽어가면서 검색하게 되어 좀처럼 발견할 수 없는 상태가 된다
  - 데이터 건수가 많으면 그만큼 입력 데이터 건수가 늘어나므로 계산량이 많아진다는 점도 당연한 이유지만 보다 더 문제가 되는 것은 '디스크를 읽고 있다'
  는 점
- 디스크는 메모리에 비해 상당히 느리다
- 메모리 내에서 계산할 수 없으면 디스크에 있는 데이터를 검색해야 하는데 디스크는 느리므로 I/O에 시간이 걸림.

### 메모리와 디스크의 속도차

- 10만~100만배 차이가 난다.

### 디스크는 왜 늦을까?

- 메모리는 전기적인 부품이므로 물리적 구조는 탐색속도와 그다지 관계가 없다.
- 디스크는 동축 상에 원반(disk)이 쌓여있고, 이 원반이 회전하며 여기서 데이터를 읽어낸다.
  - 메모리와는 달리 회전 등의 물리적인 동작을 수반함
  - 물리적인 구조가 탐색 속도에 영향을 준다
- 헤드를 데이터가 있는 원반 으로 옮기는 작업이 필요하다.(헤드의 움직임은 마이크로초, 밀리초 세계이므로 빠르다)
  - 여기서 데이터를 읽어들일 때 디스크가 회전하고 있다면 원반상 데이터의 위치가 이미 헤드보다 조금 앞으로 가버려서 원하는 위치를 읽기 위해
  원반을 한 바퀴 더 돌려야 한다.
- 탐색속도에 영향을 주는 요인
  - 디스크에서는 헤드의 이동, 원반의 회전이라는 두 가지 물리적인 이동이 필요함
    - 각각 밀리초 단위, 합해서 수 밀리초
  - 메모리는 1회 탐색할 때 마이크로초면 되지만 디스크는 수 밀리초가 걸림
  - 데이터가 뿔뿔이 흩어져서 배치되어 있고 이분탐색 등 여기저기에서 찾아야 하는 알고리즘을 사용한다고 하면 한 바퀴 회전해서
  이쪽으로 이동, 저쪽으로 이동 등 헤드와 디스크의 이동으로 상당한 시간이 거리게 된다.

### OS 레벨에서의 연구

- 디스크는 느리지만 OS는 이것을 어느 정도 커버하는 작용을 함
  - 연속된 데이터를 같은 위치에 쌓음
  - 데이터를 읽을 때 1바이트씩 읽는 것이 아닌 4KB 정도를 한꺼번에 읽도록 되어 있음
- 비슷한 데이터를 비슷한 곳에 두어 1번의 디스크 회전으로 읽는 데이터 수를 많게 함
  - 디스크의 회전횟수를 줄임
  - 하지만 결국 회전 1회당 밀리초 단위이므로 메모리와의 속도차를 피할 수 있는 것은 아님

### 전송속도, 버스의 속도차

- 메모리나 디스크 모두 CPU와 버스로 연결되어 있다.
- 버스의 속도에서도 상당한 차이가 난다.
- 메모리와 CPU는 상당히 빠른 버스로 연결되어 있지만 디스크는 느리다(거진 100배 이상 차이)
- SSD(Solid State Drive)는 물리적인 회전이 아니므로 Seek(탐색)은 빠르지만 버스 속도가 병목이 되거나 그 밖에 구조에 기인하는 면이 있어
역시나 메모리만큼의 속도는 나오지 않는다.

-------------

## 규모조정의 요소

### 규모조정, 확장성

- 웹 서비스에서 자주 거론되는 규모조정, 확장성은 서버를 여러 대 나열해놓고 그 서버로 부하를 분산한다는 얘기다.
- 웹 서비스는 스케일업 전략보다는 스케일아웃 전략이 주류이다.
  - 웹 서비스에 적합한 형태이고 비용이 저렴하다는 점과 시스템 구성에 유연성이 있다는 점에 스케일아웃을 사용
- 시스템 구성의 유연성이란 부하가 적을 때는 최소한으로 투자하고 부하가 높아짐에 따라 확장해가기 쉽다는 것

### 규모조정의 요소

- 스케일아웃은 하드웨어를 횡으로 전개해서 확장성을 확보
  - CPU 부하의 확장성을 확보하기는 쉬움
  - HTTP 요청을 받아 DB에 질의하고 DB로부터 응답받은 데이터를 가공해 HTML로 클라이언트에 반환할 때는 기본적으로 CPU 부하만 소요되는 부분
- DB 서버 측면에서는 I/O 부하가 걸림

### 웹 애플리케이션과 부하의 관계

- AP 서버는 CPu 부하만 걸리므로 분산이 간단하다
  - 데이터를 분산해서 갖고 있는 것이 아니므로 동일한 호스트가 동일하게 작업을 처리하기만 하면 분산할 수 있다
  - 대수를 늘리기만 하면 간단히 확장해갈 수 있음
  - 요청을 균등하게 분산하는 것은 로드밸런서가 해줌
- I/O 부하에는 문제가 있음
  - 데이터를 어떻게 동기화할 것인가?
  - 쓰기는 간단히 분산할 수가 없다

### DB 확장성 확보의 어려움

- 쓰기 뿐만 아니라 디스크가 느리다는 문제도 확장성 확보에 문제가 된다.
- 대규모 환경에서는 I/O 부하를 부담하고 있는 서버는 애초에 분산시키기 어려운데다가 디스크 I/O가 많이 발생하면 서버가 금새 느려진다

-----------

## 대규모 데이터를 다루기 윟나 기초지식

### 프로그래머를 위한 대규모 데이터 기초

- 대규모 데이터는 메모리에서 처리하기 어렵고 디스크는 느림
- 분산하기도 곤란함
- 데규모 데이터를 다루는 방법 두가지 관점
  - 프로그램을 작성할 때
  - 프로그램 개발의 근간이 되는 기초

### 대규모 데이터를 다루는 세 가지 급소(프로그램을 작성할 때 요령)

- 대규모 데이터를 다루는 요렁은 '어떻게 하면 메모리에서 처리를 마칠 수 있을까' 라는 점
  - 메모리에서 처리를 마쳐야하는 이유는 디스크 seek 횟수가 확장성, 성능에 크게 영향을 미치기 때문
- 다른 요령으로는 데이터량 증가에 강한 알고리즘을 사용하는 것
  - 레코드 1000만건이 있을 때 단순히 선형탐색은 1000만번 계산
  - Log Order 알고리즘을 적용하면 수십 번 만에 마칠 수 있다는 기본적인 예
- 또 다른 요령으로는 데이터 압축이나 검색기술과 같은 테크닉
  - 압축해 데이터량을 줄인다면 seek 횟수도 적어지고 메모리에 캐싱하기 쉬워짐
  - 특정 용도에 특화된 검색엔진 등을 만들어서 해당 검색 시스템을 웹 애플리케이션에서 이용하는 형태로 전환한다면 속도를 제대로 확보할 수 있음

### 대규모 데이터를 다루기 전 3대 전제지식

- OS 캐시
- 분산을 고려해서 RDBMS를 운용할 때는 어떻게 해야 하는가
- 대규모 환경에서 알고리즘과 데이터 구조를 사용한다는 것은 어떤것인가