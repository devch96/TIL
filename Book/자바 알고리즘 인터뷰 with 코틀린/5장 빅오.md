# 빅오

- 컴퓨터과학에서 빅오(Big-O)는 입력값이 커질 때 알고리즘의 실행 시간(시간 복잡도)과 함께 공간 요구 사항(공간 복잡도)
이 어떻게 증가하는지를 분류하는 데 사용되며, 알고리즘의 효율성을 분석하는 데도 매우 유용하게 활용된다

--------

## 빅오

- 빅오 표기법이란 입력 크기가 무한대로 향할 때 함수의 상한을 설명하는 수학적 표기 방법
- 점근적 실행 시간을 표기할 때 가장 널리 쓰이는 수학적 표현 기법 중 하나
- 빅오로 시간 복잡도를 표현할 때는 최고차 항만을 표기하며 계수는 무시한다
  - 4n^2 + 3n + 4 번만큼 계산하는 함수가 있다면 시간 복잡도는 최고차 항인 4n^2 만 고려
  - 계수도 무시하기 때문에 n^2만 고려
- O(1)
  - 입력값이 아무리 커도 실행시간이 일정하다
  - 크기에 전혀 영향을 받지 않기 때문에 궁극의 알고리즘이라 할 수 있지만 평생 찾지 못할 수도 있음
  - 상수 시간에 실행된다 해도 상숫값이 상상을 넘어설 정도로 매우 크다면 사실상 일정한 시간의 의미가 없음
  - 배열에서 값을 조회할 때, 연결 리스트의 끝에 값을 삽입할 때, 해시 테이블의 조회 및 삽입 등
- O(log n)
  - 컴퓨터과학에서는 주로 밑인 2를 생략하여 log n으로 표현
  - 로그는 매우 큰 입력값에도 크게 영향을 받지 않는 마법과 같은 함수
  - 거의 최고의 알고리즘
  - 이진 검색
- O(n)
  - 정확히 입력값의 크기만큼 실행 시간에 영향을 받음
  - 실행 시간이 선형(Linear)으로 증가하기 때문에 선형 시간 알고리즘이라고도 함
  - 정렬되지 않은 리스트에서 최댓값 또는 최솟값을 찾는 경우
- O(n log n)
  - 입력값만큼 순회하며 log n의 연산이 곱해짐
  - 병합 정렬을 비롯한 효율적인 정렬 알고리즘이 이에 해당됨
  - 좋은 알고리즘이라 칭하는 대부분이 이 범주에 듬
- O(n^2)
  - 입력값의 제곱만큼 연산
  - 버블 정렬 같은 비효율적인 정렬 알고리즘이 이에 해당
  - 타임아웃이 발생하는 경우가 잦음
  - 코딩 테스트에서 알고리즘을 최적화한다고 하면 O(n^2)을 O(n log n)으로 줄이는 일이 거의 대부분
- O(2^n)
  - 정확히 로그를 반대로 뒤집은 값
  - 마법처럼 늘어남
- O(n!)
  - 입력값을 1씩 줄여가며 곱셈연산을 함
  - 재귀 호출 여러번
  - 외판원 문제를 브루트 포스로 풀이할 때
  - 가장 느린 알고리즘

### n^2과 2^n의 비교

- n이 4까지는 별 차이가 없으나 점차 차이가 나기 시작함
  - n이 15일 경우 145배 이상 차이

### 빅오를 계산하는 실용적인 방법

- 함수를 리턴으로 종료하기 직전에 연산 횟수를 헤아려보면 편함

```java
int count = 0;
public int factorial(int n) {
    if (n>= 1) {
        count++;
        return n * factorial(n - 1);
    } else {
        count++;
        return 1;
    }
}
```

### 상한과 최악

- 빅오는 상한을 의미
- 빅오메가는 하한을 의미
- 빅세타는 평균을 의미
- 빅오 표기법은 정확하게 쓰기에는 너무 길고 복잡한 함수를 적당히 정확하게 표현하는 방법일 뿐 최악의 경우/평균적인 경우의 시간 복잡도와는
아무런 관계가 없는 개념

### 분할 상환 분석

- 분할 상환 분석은 알고리즘의 복잡도를 계산할 때 알고리즘 전체를 보지 않고 최악의 경우만을 살펴보는 것은 지나치게 비관적인 이유로 등장

### 병렬화

- 일부 알고리즘은 병렬화로 실행 속도를 높일 수 있음
  - 딥러닝 알고리즘
- 알고리즘 자체의 시간 복잡도 외에도 이처럼 알고리즘이 병렬화가 가능한지 여부는 알고리즘의 우수성을 평가하는 매우 중요한 척도 중 하나

### 복잡도의 특징

- 알고리즘은 흔히 시간과 공간이 트레이드오프 관계를 이룬다 라고 함
- 실행 시간이 빠른 알고리즘은 공간을 많이 사용하고 공간을 적게 차지하는 알고리즘은 실행 시간이 느리다는 의미

---------

## 자바 컬렉션 프레임워크의 빅오

### 리스트 시간 복잡도

- ArrayList
  - 인덱스 끝에 삽입: O(1) 가끔 O(n)
  - 인덱스 중간에 삽입: O(n)
  - 인덱스 끝에서 삭제: O(1)
  - 인덱스 중간에서 삭제: O(n)
  - 조회: O(1)
- LinkedList
  - 인덱스 끝에 삽입: O(1)
  - 인덱스 중간에 삽입: 탐색 O(n), 삽입 O(1)
  - 인덱스 끝에서 삭제: O(1)
  - 인덱스 중간에서 삭제: 탐색 O(n), 삭제 O(1)
  - 조회: O(n)
- ArrayList는 동적 배열
- 동적 배열인 ArrayList의 인덱스 끝에 엘리먼트를 삽입하는 것은 O(1)에 바로 가능
  - 공간이 가득 찰 경우 더블링이 일어나고 O(n)이 소요됨
  - 분할 상환 분석에 따른 시간 복잡도는 여전히 O(1)
- 연속된 배열 구조에서는 중간에 삽입할 수 있는 방법이 없기 때문에 신규 엘리먼트를 포함하여 전체를 새로운 공간에 복사해야 하며
O(n)이 소요됨
- 인덱스 끝에서 삭제는 O(1)에 가능하지만 마찬가지로 중간에서 삭제하려면 복사해야 해서 O(n)
- 어느 위치에 있든 인덱스를 지정하면 O(1)에 조회가 가능
- LinkedList는 연결 리스트
- 인덱스 끝에 삽입이 O(1)에 바로 가능하지만 중간에 삽입하려면 해당 위치까지 거슬러 내려가야 하기에 탐색에 O(n)이 필요
  - 대부분 O(n)으로 지칭함
  - 하지만 탐색보다 삽입이 더 큰 비용이 들기 때문에 그다지 느리지 않음
- 연결 리스트는 조회 시 매번 탐색해야 하므로 O(n)

```java
List<Integer> arrayList = new ArrayList<>();
for ( int i = 0; i < 100000000; i++) {
    arrayList.add(1);
}

List<Integer> linkedList = new LinkedList<>();
for (int i = 0; i < 100000000; i++) {
    linkedList.add(1);
}
```

- ArrayList 삽입시간 2265밀리초(O(1)이다 더블링 걸리면 O(n))
- LinkedList 삽입시간 17231밀리초(O(1))
- 시간 복잡도는 O(1) 이지만 LinkedList의 경우 메모리를 할당해야 하는 등의 훨씬 더 비싼 작업이 수행됨
- 시간 복잡도에서 생략된 상수 항이 매우큰 것
- 컴퓨터과학에서 O(1)은 가장 빠른 작업이며 이론적으로는 가장 빠르게 실행돼야 하지만 실무에서는 느리게 실행되는 경우가 있으므로 주의가 필요함
- 비슷한 시간 복잡도라도 ArrayList는 인덱스 끝에서의 삽입과 조회가 빠르고, LinkedList는 인덱스 중간에서의 삽입과 삭제가 빠름

### 맵 시간 복잡도

- HashMap은 추가, 삭제, 조회 모두 O(1)에 가능
  - 키 충돌이 발생하면 O(n)
- LinkedHashMap은 HashMap과 동일한 O(1)이지만 연결 리스트를 추가로 활용하는 특성상 살짝 더 느림
  - 리스트처럼 수십배씩 차이가 나진 않음

### 데크 시간 복잡도

- 양쪽에서 삽입과 삭제를 할 수 있는 스택과 큐의 연산을 모두 갖고 있는 독특한 자료형
- 원래 자료형의 성격으로 보자면 이중 연결 리스트가 어울리지만 동적 배열로 구현된 ArrayDeque가 좀 더 널리 사용됨
- 삽입, 추출 O(1)