# 컴퓨터 아키텍처와 운영체제

- 컴퓨터 아키텍처라는 말은 컴퓨터의 여러 구서요소를 배치하는 방법
  - 도리스식 이오니아식

## 기본적인 구조 요소들

- 가장 흔한 두 가지 컴퓨터 구조
  - 폰 노이만 구조
  - 하버드 구조
- 두 구조의 유일한 차이는 메모리 배열 뿐
- 폰 노이만 구조는 동시에 명령어와 데이터를 가져올 수 없기 때문에(데이터 버스와 주소 버스가 하나) 약간 느리고 하버드 구조는
동시에 명령어와 데이터를 가져올 수 있어서 좀 더 빠르지만 두 번째 메모리를 처리하기 위한 버스가 더 필요함

### 프로세스 코어

- 여러 CPU를 활용할 수 있도록 프로그램을 병렬화하는 문제는 아주 많은 수학 계산이 필요한 몇몇 경우에는 잘 작동하지만 일반적인 경우에는 어렵다
- GUI를 제공하는 초기 워크스테이션에서는 여러 프로그램을 동시에 실행할 수 있다는 점이 큰 이점
- 반도체 회로 크기가 줄어들면서 비용도 낮아지고, CPU를 더 빠르게 만듦으로써 더 나은 성능을 달성했지만 회로 크기는 줄어드는데 기계가 빨라져서 전력을 더 많이
소모하게 되면서 단위 면적당 열 발생은 더 많아짐
- CPU라고 부르는 것을 요즘은 프로세스 코어라고 부르고 코어가 여럿 들어가는 멀티코어 프로세서가 이제는 일반적으로 쓰임

### 마이크로프로세서와 마이크로컴퓨터

- 메모리와 I/O 프로세서 코어가 같은 패키지에 들어 있지 않으면 마이크로프로세서라고 부름
- 모든 요소를 한 칩 안에 패키징하면 마이크로컴퓨터라고 부름
- 칩 안에서 메모리가 차지하는 영역이 크기 때문에 일반적으로 마이크로컴퓨터가 덜 강력함
- 마이크로프로세서는 보통 큰 시스템에 들어가는 부품으로 쓰이고 마이크로컴퓨터는 식기세척기 등에서 찾을 수 있는(단일 칩으로 된) 작은 컴퓨터

## 프로시저, 서브루틴, 함수

- 함수(또는 프로시저, 서브루틴)는 코드를 재사용하는 주요 수단
  - (프로그래밍) 언어에 따라 부르는 이름만 다를 뿐
- 함수를 작성하고 호출(영어로는 invoke 혹은 call)할 수 있음
  - 코드를 두 번 작성하지 않아도 됨
- 함수를 호출하는 부분에서 함수를 실행하고 다시 원래 자리로 돌아올 방법이 필요함
  - 원래 자리를 기억해야 함
  - 프로그램 카운터 값

## 스택

- 재귀 함수가 제대로 작동하려면 반환 주소를 여럿 저장할 수 있어야 함
  - 함수에서 호출 지점으로 반환할 때 저장된 주소 중 어떤 주소를 사용할지 결정할 수 있어야 함
- 스택은 단지 반환 주소만 저장하기 위한 장소가 아닌 지역 변수도 저장한다
  - 스택에 저장되는 데이터의 모음을 스택 프레임이라고 부름

## 인터럽트

- 실행 중인 프로그램을 잠깐 중단시켜서 주의를 기울여야 하는 외부의 요소에 대응할 수 있는 방법이 필요
  - 실행 장치에 새로운 하드웨어 기능을 추가
- 프로세서 대부분은 인터럽트 시스템이 들어감
- 인터럽트 시스템은 적절한 신호가 들어오면 CPU 실행을 잠깐 중단시킬 수 있는 핀이나 전기 연결을 포함함
  - 핀은 칩에 연결된 전기적 접점
1. CPU가 주의를 기울여야 하는 주변장치는 인터럽트 요청을 생성함
2. 프로세서는 현재 실행 중인 명령어를 끝까지 실행하고 잠시 중단시킨 뒤 인터럽트 핸들러라는 전혀 다른 프로그램을 실행함
3. 인터럽트 핸들러가 필요한 작업을 다 마치고 나면 원래 실행 중이던 프로그램이 중단된 위치부터 다시 실행을 계속함

- 고려해야 할 요소
  - 인터럽트에 대한 응답 시간
    - 배달 기사(인터럽트한 프로그램)에게 시간을 너무 많이 소모하면 쿠키(원 프로그램)가 타버림
    - 인터럽트 처리(인터럽트에 대응하는 것을 서비스라고 말함)를 정해진 시간에 끝내야 함
  - 인터럽트를 서비스하고 나중에 다시 원래대로 돌아오기 위해서는 현재 상태를 저장할 방법이 필요함
    - 인터럽트가 걸린 시점에 실행 중이던 프로그램이 레지스터에 어떤 값을 저장하고 있었다면 인터럽트 핸들러는
    그 레지스터를 저장했다가 나중에 원래 프로그램으로 돌아오기 전에 레지스터값을 복구해줘야 함
    - 인터럽트 시스템은 서비스 후 돌아올 프로그램 위치를 스택에 저장함
- 컴퓨터가 인터럽터 핸들러 위치를 찾는것은 인터럽트 핸들러 주소를 저장하기로 약속한 메모리 주소가 존재
  - 여러 인터럽트 벡터가 들어있고, 각 인터럽트 벡터는 CPU가 지원하는 각 인터럽트에 대한 핸들러 주소를 지정함
  - 벡터란 메모리 위치를 가리키는 포인터일 뿐 아니라 어디로 가라는 화살표와 같음
- 운영체제는 일종의 가상 인터럽트나 소프트웨어 인터럽트 시스템을 제공함
  - 유닉스는 시그널
  - 이벤트

## 상대 주소 지정

- 여러 프로그램을 동시에 실행하려면?
  - 각 프로그램을 서로 전환시켜줄 관리자 프로그램
    - 운영체제 또는 운영체제 커널(kernel, 중심)이락 부름
  - OS는 시스템 프로그램, 나머지 모든 프로그램을 사용자 프로그램 혹은 프로세스라 부름
  - OS는 타이머를 사용해 사용자 프로그램을 전환시켜줄 때가 됐는지 판단함
    - 사용자 프로그램의 실행 시간을 조절하는 스케줄링 기법을 시분할이라고 함
  - 프로그램을 메모리로 불러들이려면 시간이 걸리기때문에 메모리로 불러오되 각 프로그램에게 각기 다른 공간을 허용할 수 있으면
  훨씬 더 빠르게 시분할 실행이 가능함
- 상대 주소 지정은 명령어에 들어 있는 주소를 0부터 시작하는 위치로 해석하지 않고 명령어의 주소를 기준으로 하는 상대적인 주소로 해석한다
  - 프로그램을 메모리의 원하는 위치로 자유롭게 재배치할 수 있음

## 메모리 관리 장치

- 멀티태스킹 환경에서 프로그램에 버그가 있으면?
  - 프로그램2에 버그가 있어 프로그램1이 차지한 메모리를 덮어쓰거나 OS의 메모리를 덮어쓴다면?
  - 의도적으로 시스템에 실행중인 다른 사람의 프로그램을 들여다보거나 변경하는 프로그램을 작성한다면?
- 각 프로그램을 분리해서 이런 시나리오가 아예 불가능
  - 메모리 관리 장치(MMU, Memory Management Unit)
- MMU가 들어 있는 시스템은 가상 주소와 물리 주소를 구분한다
  - MMU는 가상 주소를 물리 주소로 변환해줌
- MMU는 가상 메모리 주소를 두 부분으로 나눔
  - 주소의 하위부분은 물리적 주소 범위
  - 상위 부분은 페이지 테이블이라는 RAM 영역을 통해 주소를 변환

## 가상 메모리

- 운영체제는 희소한 하드웨어 자우너을 사용하려고 경합하는 프로그램들 사이의 자원 분배를 관리함
  - OS가 CPU 자체에 대한 접근을 관리하는 방식
  - 메모리도 역시 OS
- OS는 MMU를 사용해 사용자 프로그램에게 가상 메모리를 제공함
- OS는 현재 필요하지 않은 메모리 페이지를 더 느리지만 더 용량이 큰 대용량 저장장치인 디스크로 옮김(스왑 아웃이라 부름)
- 스왑 아웃한 페이지에 프로그램이 접근하면 운영체제는 필요한 메모리 공간을 확보하고 요청받은 페이지를 다시 메모리로 불러들임(스왑 인)
- 이런 식으로 페이지 처리하는 것을 요구불 페이징이라 부름
- 스와핑이 일어나면 시스템 성능이 크게 저하되지만 메모리가 부족해서 프로그램을 실행도 못 하는 것 보다는 느리더라도 스와핑을 통해 실행하는 편이 더 남

## 시스템 공간과 사용자 공간

- 멀티태스킹 시스템은 모든 프로그램에게 자신이 컴퓨터 안에서 실행되는 유일한 프로그램이라는 환상을 심음
  - MMU는 각 프로세스에게 자신만의 메모리 주소 공간을 제공해서 환상을 키움
- 하지만 사용자 프로그램이 MMU의 설정을 마음대로 바꿀 수 있다면 MMU가 프로그램을 서로 격리시키지 못함
- CPU에는 컴퓨터가 시스템 모드에 있는지 사용자 모드에 있는지 결정하는 비트가 레지스터 안에 들어 있음
  - I/O를 처리하는 명령어 등 일부 명령어는 특권 명령이라 시스템 모드에서만 실행할 수 있음
  - 트랩이나 시스템 콜이라고 부르는 특별한 명령어를 통해 사용자 모드에서 실행 중인 프로그램이 시스템 모드 프로그램(OS)에게 요청을 보낼 수 있음

## 메모리 계층과 성능

- CPU와 메모리가 같은 속도로 작업했을 때는 상관없지만 CPU가 빨라진것에 비해 메모리는 그렇게까지 빨라지지 못해 빠른 CPU가 느린 메모리를 기다리느라고
아무 일도 하지 않는 경우를 줄이기 위해 온갖 방법을 다 사용함
- 가상 메모리와 스와핑은 메모리 계층이라는 개념을 소개
- CPU는 주 메모리보다 빠르고 그것을 기다리느라 시간을 소비하는 현상을 해결하기 위해 캐시라는 하드웨어를 CPU에 추가했다
  - 분기가 없는 경우 프로그램 메모리를 순서대로 읽어오고, 프로그램이 사용하는 데이터가 한데 모여있는 경우가 많음
- CPU 메모리 컨트롤러 하드웨어는 메모리에서 연속된 열에 있는 데이터를 한꺼번에 가져옴
  - 대부분 연속된 위치에 있는 데이터가 필요하기 때문
- 메모리에 접근하는 패턴이 순차적이 아니여서 캐시 실패가 일어나도 CPU는 고속 메모리 접근 모드가 가능하기 때문에 좀 더 유리함
  - 캐시 실패란 캐시에 읽어야 하는 내용이 없어 메모리를 읽어야 하는 경우
- 캐시 메모리에도 몇 가지 계층이 있음
  - CPU에서 멀어질수록 캐시는 더 느려지고 ㅋ더 커짐
    - L1, L2, L3

